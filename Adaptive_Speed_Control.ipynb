{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORu98voLfLBE",
        "outputId": "60c478b3-36c2-4351-af72-070a1d45cc85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Q-learning parameters\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.9\n",
        "num_states = 10  # Speed levels\n",
        "num_actions = 3  # Accelerate, Decelerate, Maintain\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "def choose_action(state):\n",
        "    return np.argmax(q_table[state])\n",
        "\n",
        "# Simulating training\n",
        "for episode in range(1000):\n",
        "    state = np.random.randint(0, num_states)\n",
        "    action = choose_action(state)\n",
        "    next_state = max(0, min(num_states - 1, state + action - 1))\n",
        "    reward = -1 if next_state < 5 else 1  # Sample reward logic\n",
        "    q_table[state, action] = q_table[state, action] + learning_rate * (reward + discount_factor * np.max(q_table[next_state]) - q_table[state, action])\n",
        "\n",
        "print(\"Trained Q-Table:\", q_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IgbmJ5XfQKF",
        "outputId": "4cf37a46-d0e3-4998-dd1d-4f4dc2ae8e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Q-Table: [[-1.48542229 -1.48542229 -0.11486448]\n",
            " [-1.15074913 -1.13615128  1.24713731]\n",
            " [-0.49129723 -0.4900995   2.81071577]\n",
            " [-0.28       -0.29701     4.70680295]\n",
            " [-0.1        -0.1         6.71781463]\n",
            " [-0.1         6.51906886  0.        ]\n",
            " [ 6.61642387  0.          0.        ]\n",
            " [ 6.53891564  0.          0.        ]\n",
            " [ 6.26855641  0.          0.        ]\n",
            " [ 6.3879767   0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "data = {'speed': [30, 40, 50, 60, 70, 80, 90, 100],\n",
        "        'distance': [100, 80, 60, 40, 20, 10, 5, 2]}  # Example distances\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Q-learning parameters (adjust as needed)\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.9\n",
        "num_states = 10  # Discretize speed (adjust based on data range)\n",
        "num_actions = 3  # Accelerate, decelerate, maintain\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "\n",
        "def discretize_speed(speed):\n",
        "  # Discretize speed into states (adjust ranges based on your data)\n",
        "  if speed < 30: return 0\n",
        "  elif speed < 40: return 1\n",
        "  elif speed < 50: return 2\n",
        "  elif speed < 60: return 3\n",
        "  elif speed < 70: return 4\n",
        "  elif speed < 80: return 5\n",
        "  elif speed < 90: return 6\n",
        "  elif speed < 100: return 7\n",
        "  else: return 9 # Cap at max speed\n",
        "\n",
        "\n",
        "def choose_action(state):\n",
        "  return np.argmax(q_table[state])\n",
        "\n",
        "\n",
        "# Training loop (adjust based on your data)\n",
        "for _ in range(1000): # Training episodes\n",
        "  current_speed = np.random.choice(df['speed'])\n",
        "  current_state = discretize_speed(current_speed)\n",
        "  current_distance = df[df['speed'] == current_speed]['distance'].iloc[0]\n",
        "\n",
        "  action = choose_action(current_state)\n",
        "\n",
        "  # Simulate speed change based on action\n",
        "  if action == 0:  # Accelerate\n",
        "      new_speed = min(100, current_speed + 5) # Limit maximum speed\n",
        "  elif action == 1:  # Decelerate\n",
        "      new_speed = max(30, current_speed - 5) # Limit minimum speed\n",
        "  else: #Maintain\n",
        "      new_speed = current_speed\n",
        "\n",
        "  next_state = discretize_speed(new_speed)\n",
        "\n",
        "  # Reward function (consider distance, speed limit, etc.)\n",
        "  reward = 0\n",
        "  if current_distance > 0:\n",
        "    reward = - (current_distance - 5)/10 + (new_speed/50) # Sample reward (adjust based on needs)\n",
        "\n",
        "  q_table[current_state, action] = q_table[current_state, action] + learning_rate * (reward + discount_factor * np.max(q_table[next_state]) - q_table[current_state, action])\n",
        "\n",
        "# Prediction\n",
        "current_speed = 60\n",
        "current_state = discretize_speed(current_speed)\n",
        "predicted_action = choose_action(current_state)\n",
        "\n",
        "\n",
        "if predicted_action == 0:\n",
        "    print(\"Recommended Action: Accelerate\")\n",
        "elif predicted_action == 1:\n",
        "    print(\"Recommended Action: Decelerate\")\n",
        "else:\n",
        "    print(\"Recommended Action: Maintain Speed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaJnh8HvfZms",
        "outputId": "6a63783f-dda8-42c1-c9b2-d4acd04e823f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Action: Accelerate\n"
          ]
        }
      ]
    }
  ]
}